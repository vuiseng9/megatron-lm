{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "llama3_8b_fp8",
            "type": "debugpy",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {},
            "cwd": "${workspaceFolder}/megatron-lm/examples/llama",
            "module": "torch.distributed.run",
            "args": [
                "--nproc_per_node", "1",
                "--nnodes", "1",
                "--node_rank", "0",
                "--master_addr", "localhost",
                "--master_port", "6000",
                "../..//pretrain_gpt.py",
                "--use-mcore-models",
                "--num-layers", "32",
                "--hidden-size", "4096",
                "--ffn-hidden-size", "14336",
                "--num-attention-heads", "32",
                "--group-query-attention",
                "--num-query-groups", "8",
                "--kv-channels", "128",
                "--seq-length", "4096",
                "--max-position-embeddings", "4096",
                "--position-embedding-type", "rope",
                "--rotary-base", "1000000",
                "--rotary-percent", "1.0",
                "--attention-dropout", "0.0",
                "--hidden-dropout", "0.0",
                "--swiglu",
                "--init-method-std", "0.0134",
                "--attention-backend", "fused",
                "--apply-layernorm-1p",
                "--untie-embeddings-and-output-weights",
                "--disable-bias-linear",
                "--micro-batch-size", "1",
                "--global-batch-size", "128",
                "--train-samples", "10000",
                "--lr-decay-samples", "1949218748",
                "--lr-warmup-samples", "3906252",
                "--lr", "0.00015",
                "--min-lr", "0.00001",
                "--decoupled-lr", "5.0e-4",
                "--decoupled-min-lr", "4.5e-5",
                "--lr-decay-style", "cosine",
                "--clip-grad", "1.0",
                "--weight-decay", "0.1",
                "--adam-beta1", "0.9",
                "--adam-beta2", "0.95",
                "--bf16",
                "--grad-reduce-in-bf16",
                "--cross-entropy-loss-fusion",
                "--calculate-per-token-loss",
                "--manual-gc",
                "--empty-unused-memory-level", "1",
                "--exit-duration-in-mins", "235",
                "--use-distributed-optimizer",
                "--overlap-grad-reduce",
                "--overlap-param-gather",
                "--fp8-format", "hybrid",
                "--fp8-amax-history-len", "1024",
                "--fp8-amax-compute-algo", "max",
                "--fp8-param-gather",
                "--tensor-model-parallel-size", "1",
                "--context-parallel-size", "1",
                "--sequence-parallel",
                "--mock-data",
                "--tokenizer-type", "NullTokenizer",
                "--vocab-size", "128256",
                "--data-cache-path", "./sandbox_run/benchmark_cache_llama3_8b_fp8",
                "--tiktoken-pattern", "v2",
                "--split", "99,1,0",
                "--no-create-attention-mask-in-dataloader",
                "--no-mmap-bin-files",
                "--num-workers", "1",
                "--log-interval", "1",
                "--eval-iters", "32",
                "--eval-interval", "100",
                "--save-interval", "1000",
                "--log-throughput",
                "--profile",
                "--profile-step-start", "4",
                "--profile-step-end", "6",
                "--ckpt-format", "torch_dist",
                "--distributed-timeout-minutes", "60",
                "--save", "./sandbox_run/checkpoints/llama3_8b_fp8",
                "--load", "./sandbox_run/checkpoints/llama3_8b_fp8",
                "--tensorboard-dir", "./sandbox_run/tensorboard_logs/llama3_8b_fp8"
            ]
        },
        {
            "name": "gpt3_345m_debug",
            "type": "debugpy",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {},
            "cwd": "${workspaceFolder}/megatron-lm/examples/gpt3",
            "module": "torch.distributed.run",
            "args": [
                "--nproc_per_node", "1",
                "--nnodes", "1",
                "--master_addr", "localhost",
                "--master_port", "6000",
                "../../pretrain_gpt.py",
                "--num-layers", "12",
                "--hidden-size", "512",
                "--num-attention-heads", "8",
                "--seq-length", "1024",
                "--max-position-embeddings", "1024",
                "--attention-backend", "auto",
                "--micro-batch-size", "1",
                "--global-batch-size", "1536",
                "--train-iters", "500000",
                "--weight-decay", "0.1",
                "--adam-beta1", "0.9",
                "--adam-beta2", "0.95",
                "--init-method-std", "0.006",
                "--clip-grad", "1.0",
                "--bf16",
                "--lr", "6.0e-5",
                "--lr-decay-style", "cosine",
                "--min-lr", "6.0e-6",
                "--lr-warmup-fraction", ".001",
                "--lr-decay-iters", "430000",
                "--tensor-model-parallel-size", "1",
                "--pipeline-model-parallel-size", "1",
                "--data-path", "./owt-ds/openwebtext-10k_text_document",
                "--vocab-file", "./owt-ds/gpt2-vocab.json",
                "--merge-file", "./owt-ds/gpt2-merges.txt",
                "--split", "949,50,1",
                "--log-interval", "5",
                "--save-interval", "10000",
                "--eval-interval", "1000",
                "--save", "./sandbox_run/ckpt",
                "--load", "./sandbox_run/ckpt",
                "--eval-iters", "10",
                "--tensorboard-dir", "./sandbox_run/tb",
                "--wandb-entity", "vchua",
                "--wandb-project", "mlm-sandbox",
                "--wandb-exp-name", "251001_233537_gpt3_345m_gpu1_tp1_pp1"
            ]
        },
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        }
    ]
}